---
title: "gDR suite"
author: "gDR team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Running the drug response processing pipeline}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction {#intro}

Over decades, many departments across gRED and Roche have generated large amounts of drug response screening data using Genentech's rich resources of drug compounds inventory. While we've invested intensive labor and time to generate these data, they are not analyzed in a standardized manner for meaningful comparison. On one hand, large screens are performed across many cell lines and drugs in a semi-automated manner. On the other hand, small-scale studies, which focused on factors that contribute to sensitivity and resistance to certain therapy, are generally performed by each individual scientist with limited automation. These are complementary approaches but were rarely handled the same way. Commercial softwares are available for analyzing large datasets, whereas researchers in the latter case often
Here we propose a suite of computational tools that enable the processing, archiving, and visualization of drug response data from any experiment, thus ensuring reproducibility and implementation of the F.A.I.R. principles. 

gDR suite consists of several modules connecting with each other to systematically analyze and store drug response data. The core of gDR lies in its database which hosts thousands of experiments and datasets generated by different individual scientists. It includes large panel drug screens with simple design of single agent treatment as well as more complex combinational treatments - either with 2nd drug as a fixed dose or a matrix. When conditions are further complicated with co-treatment of ligands or with cell line genetic perturbations, e.g shRNA treatment or resistant cell lines obtained from a previous screen, as long as the conditions are well defined in metadata, these data will be compatible with all other types of data. 

To use the gDR database, the users first need to upload the metafiles, which include metadata to run the experiments, template files which contain the drugs and cell lines used, and the raw data output files obtained from a plate reader or a scanner into an interactive web application build with R Shiny. Quality control, data normalization, and metric calculations are performed by the processing software before the data is pushed and stored in gDR database. Besides the R shiny app, data processed by other commercial softwares or from other databases can also be easily pushed into the gDR database through the REST API.

Once the data is stored in the database, there are multiple ways to visualize the data depending on the scientific needs. Weâ€™ve developed an R package as well as another R-shiny based web application to fetch data. The users can search and select experiments defined in metaprojects based on his/her own needs to plot and analyze the data.

For now we share our initial gDR suite for loading, processing, and managing the data.

## R Packages {#rpackages}

gDR suite consists of a few packages that power our app and make it a comprehensive tool.
All the packages under the gDR umbrella are stored in the [gDR platform GitHub organization](https://github.roche.com/gdrplatform/).

We are happy to share with you our packages for importing, processing and managing gDR data:
* gDRimport
* gDRcore
* gDRutils
* gDRtestData


## Usage

### Input data

gDR suite requires three types of data that should be provided: manifest, template(s), and raw data.

Exemplary data can be found here:

```{r, echo=TRUE, results='asis'}
library(gDR)

# Define path for data stored in gDR package
dataDir <- system.file("extdata", "data1", package = "gDRimport")

# Extract path for example raw_data
manifest <- list.files(dataDir, pattern = "manifest", full.names = TRUE)
template <- list.files(dataDir, pattern = "Template", full.names = TRUE)
raw_data <- list.files(dataDir, pattern = "RawData", full.names = TRUE)

manifest
template
raw_data
```

Data can be easily imported by:

```{r, echo=TRUE, results='asis', warning=FALSE, results='hide', message=FALSE}
# Import data
imported_data <- import_data(manifest, template, raw_data)
```

and finally processed by:

```{r, echo=TRUE, results='asis', warning=FALSE, results='hide', message=FALSE}
# Run gDR pipeline
SE <- runDrugResponseProcessingPipeline(imported_data)
```

```{r, echo=TRUE}
SE
```

The function will create a SummarizedExperiment of raw data and then will normalize, average, and calculate drug-response metrics of the data.

SummarizedExperiment object is made up of multiple assays, such as:

```{r, echo=TRUE}
SummarizedExperiment::assayNames(SE)
```

that can be easily transformed to `data.table` format using `convert_se_assay_to_dt` function:

```{r, echo=TRUE, eval=FALSE}
convert_se_assay_to_dt(SE, "Metrics")
```

```{r, echo=FALSE}
library(kableExtra)
kbl(convert_se_assay_to_dt(SE, "Metrics")) %>%
  kable_paper() %>%
  scroll_box(width = "700px", height = "300px")
```

