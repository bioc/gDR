---
title: "gDR suite"
author: "gDR team"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Running the drug response processing pipeline}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction {#intro}

Over decades, many departments across gRED and Roche have generated large amounts of drug response screening data using Genentech's rich drug compounds inventory. While extensive labor and time has been invested to generate these data, they are not analyzed in a standardized manner for meaningful comparison. On one hand, large screens are performed across many cell lines and drugs in a semi-automated manner. On the other hand, small-scale studies, which focused on factors that contribute to sensitivity and resistance to certain therapy, are generally performed by each individual scientist with limited automation. These are complementary approaches but were rarely handled the same way. Commercial softwares are available for analyzing large datasets, whereas researchers for small-scale datasets often process data ad hoc through software like PRISM.

Here, we propose a suite of computational tools that enable the processing, archiving, and visualization of drug response data from any experiment, regardless of size or , thus ensuring reproducibility and implementation of the Findable, Accessible, Interoperable, and Reusable (F.A.I.R.) principles. 

The gDR suite presents a full stack solution to systematically analyze and store drug response data. The core of gDR lies in its database which hosts thousands of experiments and datasets generated by different individual scientists. It includes large panel drug screens with simple design of single agent treatment as well as more complex combinational treatments - either with 2nd drug as a fixed dose or a matrix. When conditions are further complicated with co-treatment of ligands or with cell line genetic perturbations, e.g shRNA treatment or resistant cell lines obtained from a previous screen, as long as the conditions are well defined in metadata, these data will be compatible with all other types of data. 

The processing pipeline takes as input metadata files which includes: metadata on the experimental design, template files specifying the drugs and cell lines used, and the raw data output files obtained from a plate reader or a scanner. Quality control, data normalization, and metric calculations are performed by the processing software and then the data is pushed and stored in the gDR database. The gDR suite provides an Rshiny application for the convenience of users to upload these different metadata files. Data processed by other commercial software or data residing from other databases can also be easily pushed into the gDR database through the REST API.

Once the data is stored in the database, there are multiple ways to visualize the data depending on the scientific needs. The primary method to do is through our RShiny visualization tool 'gDRviz'. Here, users can search and select experiments  presente in the database, and use downstream visualization modules to look at dose response curves, heatmaps, etc.

For now we share our initial gDR suite for loading, processing, and managing the data.

## R Packages {#rpackages}

gDR suite consists of a few packages that power our app and make it a comprehensive tool.
All the packages under the gDR umbrella are stored in the [gDR platform GitHub organization](https://github.roche.com/gdrplatform/).

We are happy to share with you our packages for importing, processing and managing gDR data:
* gDRimport
* gDRcore
* gDRutils
* gDRtestData


## Usage

### Input data

gDR suite requires three types of data that should be provided: manifest, template(s), and raw data.

Exemplary data can be found here:

```{r, echo=TRUE, results='asis'}
library(gDR)

# Define path for data stored in gDR package
dataDir <- system.file("extdata", "data1", package = "gDRimport")

# Extract path for example raw_data
manifest <- list.files(dataDir, pattern = "manifest", full.names = TRUE)
template <- list.files(dataDir, pattern = "Template", full.names = TRUE)
raw_data <- list.files(dataDir, pattern = "^RawData", full.names = TRUE)

manifest
template
raw_data
```

Data can be easily imported by:

```{r, echo=TRUE, results='asis', warning=FALSE, results='hide', message=FALSE}
# Import data
imported_data <- import_data(manifest, template, raw_data)
```

and finally processed by:

```{r, echo=TRUE, results='asis', warning=FALSE, results='hide', message=FALSE}
# Run gDR pipeline
se <- runDrugResponseProcessingPipeline(imported_data)
```

```{r, echo=TRUE}
se
```

The processing pipeline will create a SummarizedExperiment containing raw treated and control assays and then will normalize, average, and calculate drug-response metrics from the data.

SummarizedExperiment object is made up of multiple assays, such as:

```{r, echo=TRUE}
SummarizedExperiment::assayNames(se)
```

that can be easily transformed to `data.table` format using `convert_se_assay_to_dt` function:

```{r, echo=TRUE, eval=FALSE}
convert_se_assay_to_dt(se, "Metrics")
```

```{r, echo=FALSE}
remotes::install_cran("kableExtra")
library(kableExtra)
kbl(convert_se_assay_to_dt(se, "Metrics")) |>
  kable_paper() |>
  scroll_box(width = "700px", height = "300px")
```

